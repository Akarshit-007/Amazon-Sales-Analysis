{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991c0950",
   "metadata": {},
   "source": [
    "\n",
    "# Amazon Sales Analysis — Internship Project\n",
    "\n",
    "This notebook performs a **clear, step-by-step analysis** of the Amazon sales dataset, aligned with the project objectives:\n",
    "1) Sales Overview  \n",
    "2) Product Analysis  \n",
    "3) Fulfilment Analysis  \n",
    "4) Customer Segmentation  \n",
    "5) Geographical Analysis  \n",
    "6) Business Insights & Recommendations  \n",
    "\n",
    "**How to use:**\n",
    "- Put the CSV at the path you set in `csv_path` below. By default, it looks for `./data/Amazon Sale Report.csv`.\n",
    "- Run cells **top to bottom**. Every step is explained and uses readable code (no dense one-liners).\n",
    "- Charts are generated with matplotlib and appear inline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774a0e0",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chart display settings (no custom colors/styles to keep it simple)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4514fa0e",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load the dataset (with robust encoding)\n",
    "- We try common encodings to avoid errors.\n",
    "- Adjust `csv_path` if your file is elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set your CSV path here. Suggested structure is ./data/Amazon Sale Report.csv\n",
    "csv_path = \"./data/Amazon Sale Report.csv\"\n",
    "\n",
    "# If you're running this in Colab:\n",
    "# 1) Upload the CSV using the file pane OR\n",
    "# 2) Mount Drive and point csv_path to the file on Drive.\n",
    "\n",
    "encodings_to_try = [\"utf-8\", \"latin1\", \"cp1252\"]\n",
    "last_err = None\n",
    "df = None\n",
    "for enc in encodings_to_try:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, low_memory=False, encoding=enc)\n",
    "        print(f\"Loaded CSV with encoding: {enc}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "\n",
    "if df is None:\n",
    "    # Fallback for this environment if the path above doesn't exist.\n",
    "    # You can remove this block after setting a proper csv_path.\n",
    "    try:\n",
    "        df = pd.read_csv(\"/mnt/data/Amazon Sale Report.csv\", low_memory=False, encoding=\"latin1\")\n",
    "        print(\"Loaded CSV from /mnt/data/ with latin1 encoding (fallback).\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load CSV. Last error: {last_err}\") from e\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c433aa29",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Clean and standardize columns\n",
    "- Convert column names to lowercase with underscores.\n",
    "- Detect important columns by common names.\n",
    "- Parse dates; coerce amounts/qty to numeric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize column names\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\") for c in df.columns]\n",
    "\n",
    "# Helper to find columns by candidate names\n",
    "def find_col(candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "col_order_id   = find_col([\"order_id\", \"order_id_\"])\n",
    "col_date       = find_col([\"date\", \"order_date\", \"purchase_date\"])\n",
    "col_status     = find_col([\"status\"])\n",
    "col_fulfilment = find_col([\"fulfilment\", \"fulfillment\", \"fulfillment_by\"])\n",
    "col_category   = find_col([\"category\", \"product_category\"])\n",
    "col_size       = find_col([\"size\"])\n",
    "col_qty        = find_col([\"qty\", \"quantity\"])\n",
    "col_amount     = find_col([\"amount\", \"total\", \"item_total\", \"grand_total\"])\n",
    "col_ship_city  = find_col([\"ship_city\", \"city\"])\n",
    "col_ship_state = find_col([\"ship_state\", \"state\"])\n",
    "col_b2b        = find_col([\"b2b\"])\n",
    "\n",
    "# Parse date and numerics safely\n",
    "if col_date:\n",
    "    df[col_date] = pd.to_datetime(df[col_date], errors=\"coerce\")\n",
    "\n",
    "if col_amount is None:\n",
    "    df[\"__amount__\"] = np.nan\n",
    "    col_amount = \"__amount__\"\n",
    "df[col_amount] = pd.to_numeric(df[col_amount], errors=\"coerce\")\n",
    "\n",
    "if col_qty is None:\n",
    "    df[\"__qty__\"] = 1.0\n",
    "    col_qty = \"__qty__\"\n",
    "df[col_qty] = pd.to_numeric(df[col_qty], errors=\"coerce\")\n",
    "\n",
    "# Quick info\n",
    "summary_cols = [col for col in [col_order_id, col_date, col_status, col_fulfilment, col_category, col_size, col_qty, col_amount, col_ship_city, col_ship_state, col_b2b] if col]\n",
    "print(\"Detected columns:\", summary_cols)\n",
    "df[summary_cols].head(5) if summary_cols else df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa952a6f",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Core KPIs\n",
    "We calculate:\n",
    "- Total Orders\n",
    "- Total Sales (sum of `amount`)\n",
    "- Average Order Value (AOV)\n",
    "- Date range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_orders = len(df)\n",
    "total_sales = df[col_amount].sum(skipna=True)\n",
    "avg_order_value = total_sales / total_orders if total_orders else np.nan\n",
    "date_min = df[col_date].min() if col_date else None\n",
    "date_max = df[col_date].max() if col_date else None\n",
    "\n",
    "print(f\"\"\"KPIs\n",
    "-----\n",
    "Total Orders: {total_orders:,}\n",
    "Total Sales: {total_sales:,.2f}\n",
    "Average Order Value (AOV): {avg_order_value:,.2f}\n",
    "Date Range: {date_min.date() if pd.notna(date_min) else 'N/A'} to {date_max.date() if pd.notna(date_max) else 'N/A'}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b49f977",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Sales Overview — Trends Over Time\n",
    "- We group revenue by day and plot the time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb66e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if col_date:\n",
    "    sales_over_time = (\n",
    "        df.dropna(subset=[col_date])\n",
    "          .groupby(df[col_date].dt.date)[col_amount].sum()\n",
    "          .reset_index(name=\"sales\")\n",
    "          .rename(columns={col_date:\"date\"})\n",
    "          .sort_values(\"date\")\n",
    "    )\n",
    "    display(sales_over_time.head(10))\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(sales_over_time[\"date\"], sales_over_time[\"sales\"])\n",
    "    plt.title(\"Sales Over Time (Daily)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Revenue\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No date column detected; skipping sales-over-time analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a673d8e",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Product Analysis — Categories and Sizes\n",
    "- Top categories by **revenue** and **units**.\n",
    "- Sizes by **units**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if col_category:\n",
    "    by_category = (\n",
    "        df.groupby(col_category).agg(\n",
    "            orders=(col_order_id if col_order_id else col_amount, \"count\"),\n",
    "            units=(col_qty, \"sum\"),\n",
    "            revenue=(col_amount, \"sum\")\n",
    "        ).reset_index().sort_values(\"revenue\", ascending=False)\n",
    "    )\n",
    "    display(by_category.head(10))\n",
    "    \n",
    "    # Plot top 10 categories by revenue\n",
    "    top = by_category.head(10)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(top[col_category], top[\"revenue\"])\n",
    "    plt.title(\"Top Categories by Revenue\")\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Revenue\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No category column detected; skipping category analysis.\")\n",
    "\n",
    "if col_size:\n",
    "    by_size = (\n",
    "        df.groupby(col_size).agg(\n",
    "            orders=(col_order_id if col_order_id else col_amount, \"count\"),\n",
    "            units=(col_qty, \"sum\"),\n",
    "            revenue=(col_amount, \"sum\")\n",
    "        ).reset_index().sort_values(\"units\", ascending=False)\n",
    "    )\n",
    "    display(by_size.head(10))\n",
    "    \n",
    "    # Plot top sizes by units\n",
    "    top = by_size.head(10)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(top[col_size], top[\"units\"])\n",
    "    plt.title(\"Sizes by Units Sold\")\n",
    "    plt.xlabel(\"Size\")\n",
    "    plt.ylabel(\"Units\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No size column detected; skipping size analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d64d7e",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Fulfilment Analysis — Method × Status\n",
    "- Compare order counts by fulfilment method and status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if col_fulfilment and col_status:\n",
    "    fulfilment_status = (\n",
    "        df.groupby([col_fulfilment, col_status]).size().reset_index(name=\"orders\")\n",
    "        .sort_values(\"orders\", ascending=False)\n",
    "    )\n",
    "    display(fulfilment_status.head(10))\n",
    "    \n",
    "    # Simple top-10 combo plot\n",
    "    top_fs = fulfilment_status.head(10)\n",
    "    labels = [f\"{a} | {b}\" for a,b in zip(top_fs[col_fulfilment], top_fs[col_status])]\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(labels, top_fs[\"orders\"])\n",
    "    plt.title(\"Orders by Fulfilment & Status (Top 10)\")\n",
    "    plt.xlabel(\"Fulfilment | Status\")\n",
    "    plt.ylabel(\"Orders\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Missing fulfilment or status column; skipping fulfilment analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35176ee9",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Geographical Analysis — States and Cities\n",
    "- Top states and cities by orders and revenue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03628c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if col_ship_state:\n",
    "    top_states = (\n",
    "        df.groupby(col_ship_state).agg(\n",
    "            orders=(col_order_id if col_order_id else col_amount, \"count\"),\n",
    "            revenue=(col_amount, \"sum\")\n",
    "        ).reset_index().sort_values(\"orders\", ascending=False)\n",
    "    )\n",
    "    display(top_states.head(10))\n",
    "    \n",
    "    # Plot top 10 states\n",
    "    ts = top_states.head(10)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(ts[col_ship_state], ts[\"orders\"])\n",
    "    plt.title(\"Top States by Orders\")\n",
    "    plt.xlabel(\"State\")\n",
    "    plt.ylabel(\"Orders\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No ship_state column detected; skipping state analysis.\")\n",
    "\n",
    "if col_ship_city:\n",
    "    top_cities = (\n",
    "        df.groupby(col_ship_city).agg(\n",
    "            orders=(col_order_id if col_order_id else col_amount, \"count\"),\n",
    "            revenue=(col_amount, \"sum\")\n",
    "        ).reset_index().sort_values(\"orders\", ascending=False)\n",
    "    )\n",
    "    display(top_cities.head(10))\n",
    "else:\n",
    "    print(\"No ship_city column detected; skipping city-level listing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50080d23",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Customer Segmentation (Simple Proxy)\n",
    "- If a `b2b` flag exists, use B2B vs B2C.\n",
    "- Otherwise, segment orders by order value tertiles: **Low**, **Mid**, **High**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789bf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if col_b2b and df[col_b2b].notna().any():\n",
    "    seg_table = df.groupby(col_b2b).agg(\n",
    "        orders=(col_order_id if col_order_id else col_amount, \"count\"),\n",
    "        revenue=(col_amount, \"sum\"),\n",
    "        aov=(col_amount, \"mean\")\n",
    "    ).reset_index()\n",
    "    display(seg_table)\n",
    "else:\n",
    "    # Proxy segmentation by order value\n",
    "    value = df[col_amount].fillna(0)\n",
    "    cuts = pd.qcut(value.rank(method=\"first\"), q=3, labels=[\"Low-value\", \"Mid-value\", \"High-value\"])\n",
    "    df[\"value_segment\"] = cuts\n",
    "    seg_table = df.groupby(\"value_segment\").agg(\n",
    "        orders=(col_order_id if col_order_id else col_amount, \"count\"),\n",
    "        revenue=(col_amount, \"sum\"),\n",
    "        aov=(col_amount, \"mean\")\n",
    "    ).reset_index().sort_values(\"aov\")\n",
    "    display(seg_table)\n",
    "    \n",
    "    # Pie of orders share by segment\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.pie(seg_table[\"orders\"], labels=list(seg_table[\"value_segment\"].astype(str)), autopct=\"%1.1f%%\")\n",
    "    plt.title(\"Customer Segments (Proxy)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f64217",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Business Insights & Recommendations\n",
    "- **Inventory:** Keep fast-moving categories/sizes stocked; set reorder points and safety stock.  \n",
    "- **Fulfilment:** Track on-time delivery; standardize merchant fulfilment quality to reduce returns/cancels.  \n",
    "- **Targeting:** Tailor campaigns by segment and region to improve conversion.  \n",
    "- **Forecasting:** Use trends for demand forecasting and capacity planning.  \n",
    "\n",
    "> Replace or add specific actions after reviewing your actual top categories, sizes, states, and fulfilment outcomes above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976688b4",
   "metadata": {},
   "source": [
    "\n",
    "## (Optional) 11) Export key tables for your report/README\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4cfbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an `exports` folder to save transparent CSVs if you want to include them in your repo\n",
    "import os\n",
    "os.makedirs(\"./exports\", exist_ok=True)\n",
    "\n",
    "if 'by_category' in globals():\n",
    "    by_category.to_csv(\"./exports/by_category.csv\", index=False)\n",
    "if 'by_size' in globals():\n",
    "    by_size.to_csv(\"./exports/by_size.csv\", index=False)\n",
    "if 'fulfilment_status' in globals():\n",
    "    fulfilment_status.to_csv(\"./exports/fulfilment_status.csv\", index=False)\n",
    "if 'top_states' in globals():\n",
    "    top_states.to_csv(\"./exports/top_states.csv\", index=False)\n",
    "if 'top_cities' in globals():\n",
    "    top_cities.to_csv(\"./exports/top_cities.csv\", index=False)\n",
    "if 'sales_over_time' in globals():\n",
    "    sales_over_time.to_csv(\"./exports/sales_over_time.csv\", index=False)\n",
    "if 'seg_table' in globals():\n",
    "    seg_table.to_csv(\"./exports/segments.csv\", index=False)\n",
    "\n",
    "print(\"Exports saved to ./exports (if tables existed).\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
